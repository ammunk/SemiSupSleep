{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _cholesky_factorization_precision(covariances, cov_type):\n",
    "    \n",
    "    if cov_type == 'full':\n",
    "        n_components, n_features, _ \t= covariances.shape\n",
    "        precisions_chol\t\t\t= np.empty((n_components, n_features, n_features))\n",
    "        for k in range(n_components):\n",
    "            try:\n",
    "                cov_chol\t= linalg.cholesky(covariances[k], lower = True)\n",
    "            except linalg.LinAlgError:\n",
    "                raise ValueError(\"Ill-defined covariance matrix. Try another covariance type in order to alleviate the issue\")\n",
    "\n",
    "            # return transposed of the inverse of the lower triangular matrix, as this need to be used smartly for the normal_log_prob. Note, det(A.T) = det(A)\n",
    "            precisions_chol[k]\t= linalg.solve_triangular(cov_chol, np.identity(n_features), lower = True).T\n",
    "    elif cov_type == 'tied':\n",
    "        n_features, _ \t= covariances.shape\n",
    "        try:\n",
    "            cov_chol\t= linalg.cholesky(covariances, lower = True)\n",
    "        except linalg.LinAlgError:\n",
    "            raise ValueError(\"Ill-defined covariance matrix. Try another covariance type in order to alleviate the issue\")\n",
    "         \n",
    "        precisions_chol = linalg.solve_triangular(cov_chol, np.identity(n_features), lower = True).T\n",
    "    else\n",
    "        # return transposed of the inverse of the lower triangular matrix, as this need to be used smartly for the normal_log_prob. Note, det(A.T) = det(A)\n",
    "        precisions_chol = 1. / np.sqrt(covariances)\n",
    "    \n",
    "    return precisions_chol\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _log_det_chol(lower_tri_mat, cov_type, n_features):\n",
    "    # use that the cholesky factorization is lower triangular, hence the determinant is the product of the diagonal!    \n",
    "    # https://proofwiki.org/wiki/Determinant_of_Triangular_Matrix    \n",
    "    # remember det(Sigma^-1) = det(L * L.T) = det(L) ^ 2\n",
    "    if cov_type == \"full\":       \n",
    "        return np.sum(np.log(lower_tri_mat.reshape(:,-1)[:, ::n_features + 1]), axis = 1) #Along 2. axis\n",
    "    elif cov_type == \"tied\":\n",
    "        return np.sum(np.log(np.diag(lower_tri_mat)), axis = 1)\n",
    "    elif cov_type == 'diag':\n",
    "        return np.sum(np.log(lower_tri_mat), axis = 1) \n",
    "    elif cov_type == 'diag_tied':\n",
    "        return np.sum(np.log(lower_tri_mat))\n",
    "    else\n",
    "        return n_features * np.log(lower_tri_mat)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def _log_prob_gauss(X, means, precisions_chol, cov_type):\n",
    "\n",
    "    n_samples, n_features\t= X.shape\n",
    "    n_components\t\t= means.shape\n",
    "    \n",
    "    # we use we have the precision decomposition, ie. L^-1, such that sqrt(1/det(Sigma)) = sqrt(det(Sigma^-1)), which is easily calculated using the decomposition\n",
    "    log_det\t\t\t= _log_det_chol(precisions_chol, cov_type, n_features)\n",
    "    \n",
    "    if cov_type == \"full\":\n",
    "        log_exp\t\t= np.empty(n_samples, n_components)\n",
    "        for k, (means, prec_chol) in enumerate(zip(means, precisions_chol)):\n",
    "            # Use the cholesky factorization to realize we end up with a simple dot product of the same vector for each sample n - note prec_chol = (L.T)^-1\n",
    "            diff\t\t= np.dot(X, prec_chol) - np.dot(mu,prec_chol) # N x D \n",
    "            log_exp[:, k] \t= np.sum(np.square(diff), axis = 1) #N x 1\n",
    "    elif cov_type == \"tied\":\n",
    "        log_exp\t\t= np.empty(n_samples, n_components)\n",
    "        for k, (means) in enumerate(means):\n",
    "            # Use the cholesky factorization to realize we end up with a simple dot product of the same vector for each sample n - note prec_chol = (L.T)^-1\n",
    "            diff\t\t= np.dot(X, precisions_chol) - np.dot(mu,precisions_chol) # N x D \n",
    "            log_exp[:, k] \t= np.sum(np.square(diff), axis = 1) #N x 1\n",
    "    elif cov_type == \"diag\" or cov_type == \"diag_tied\":   \n",
    "        precision2 = precisions_chol ** 2\n",
    "        log_prob = (np.sum((means ** 2 * precision2), 1) - 2. * np.dot(X, (means * precision2).T) + np.dot(X ** 2, precision2.T))         \n",
    "    elif cov_type == \"spherical\":\n",
    "        precision2 = precisions_chol ** 2\n",
    "        X_norm = np.sum(X ** 2, axis = 1)\n",
    "        log_prob = np.sum(means ** 2, 1) * precision2 - 2 * np.dot(X, means.T * precision2) + np.outer(X_norm, precision2)\n",
    "    elif cov_type == \"spherical_tied\":\n",
    "        precision2 = precisions_chol ** 2\n",
    "        X_norm = np.sum(X ** 2, axis = 1)\n",
    "        log_prob = np.sum(means ** 2, 1) * precision2 - 2 * np.dot(X, means.T * precision2) + np.outer(X_norm, np.tile(precision2,n_components))\n",
    "            \n",
    "    # utilize the broadcasting, which sums along equal size dimension (i.e. n_components)\n",
    "    # also use that the determinant of the inverse is one over the determinant of non-inverse\n",
    "    # the log (again using cholesky) takes the 0.5 factor from the last term\n",
    "    log_prob_gauss\t\t= - 0.5 * (n_features * np.log(2 * np.pi) + log_exp) + log_det\n",
    "    \n",
    "    return log_prob_gauss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _estimate_parameters(X, y, resp, class_resp, components, cov_type, label_idx)\n",
    "    n_samples, _\t= X.shape\n",
    "    components\t= _components(n_samples, nk)\n",
    "    means\t\t= _means(X, resp, nk)\n",
    "    if cov_type == \"full\":\n",
    "        covariances\t= _covariance_full(X, resp, means, nk)\n",
    "    elif cov_type == \"full_tied\":\n",
    "        covariances\t= _covariance_full_tied(X, resp, means, nk)\n",
    "    elif cov_type == \"diag\":\n",
    "        covariances\t= _covariance_diag(X, resp, means, nk)\n",
    "    elif cov_type == \"diag_tied\":\n",
    "        covariances\t= _covariance_diag_tied(X, resp, means, nk)\n",
    "    elif cov_type == \"spherical\":\n",
    "        covariances\t= _covariance_spherical(X, resp, means, nk)\n",
    "    elif cov_type == \"spherical_tied\":\n",
    "        covariances\t= _covariance_spherical_tied(X, resp, means, nk)\n",
    "        \n",
    "    precisions_chol = _cholesky_factorization_precision(covariances, cov_type)\n",
    "    \n",
    "    p_ak\t\t= _class_prob(resp, class_resp, y, label_idx)\n",
    "    \n",
    "    return components, means, precisions_chol, p_ak\n",
    "\n",
    "def _covariance_full(X, resp, means, nk):\n",
    "    n_components, n_features \t= means.shape\n",
    "    \n",
    "    covariances\t\t\t= np.empty((n_components, n_features, n_features))\n",
    "    for k in range(n_components):\n",
    "        diff\t\t\t= X - means[k]\n",
    "        covariances[k]\t\t= np.dot(resp[:,k] * diff.T, diff) / nk[k]\n",
    "    \n",
    "    covariances\t= np.tile(np.average(covariances, axis = 0), (n_components_, 1, 1))\n",
    "    return covariances\n",
    "\n",
    "def _covariance_full_tied(X, resp, means, nk):\n",
    "    n_components, n_features \t= means.shape\n",
    "    covariances\t\t\t= np.empty(n_features, n_features))\n",
    "\n",
    "    avg_X2 = np.dot(X.T, X)\n",
    "    avg_means2 = np.dot(nk * means.T, means)\n",
    "    covariance = avg_X2 - avg_means2\n",
    "    covariance /= nk.sum()\n",
    "    return covariance\n",
    "    \n",
    "def _covariance_diag(X, resp, means, nk):   \n",
    "    n_components, n_features \t= means.shape\n",
    "    covariances\t\t\t= np.empty((n_components, n_features))\n",
    "    \n",
    "    #Using summation trick see notes/pictures\n",
    "    avg_X2 = np.dot(resp.T, X * X) / nk[:, np.newaxis]\n",
    "    avg_means2 = means ** 2\n",
    "    covariances = avg_X2 - avg_means2\n",
    "    \n",
    "    #Using Sklearns method to test. Delete this again\n",
    "    avg_X_means = means * np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "    print \"Is using the summation trick equal to sklearns method: \" + covariances == avg_X2 - 2 * avg_X_means + avg_means2\n",
    "    \n",
    "    return covariances\n",
    "\n",
    "def _covariance_diag_tied(X, resp, means, nk):   \n",
    "    n_components, n_features \t= means.shape\n",
    "    covariances\t\t\t= np.empty((n_features))\n",
    "    \n",
    "    avg_X2 = np.sum(X ** 2, axis = 0)\n",
    "    avg_means2 = np.dot(nk, means**2)\n",
    "    covariances = (avg_X2 - avg_means2)\n",
    "    covariances /= nk.sum()\n",
    "    \n",
    "    return covariances\n",
    "    \n",
    "def _covariance_spherical(X, resp, means, nk):\n",
    "    \n",
    "    return _covariance_diag(X, resp, means, nk).mean(1)\n",
    "\n",
    "def _covariance_spherical_tied(X, resp, means, nk):\n",
    "    \n",
    "    return _covariance_diag_tied(X, resp, means, nk).mean(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _initialize(self, X, n_init):\n",
    "\n",
    "        if self.unlabel_independent_:\t\t\n",
    "            self.class_resp\t\t= np.zeros((len(self.classes_), self.n_components_))\n",
    "    \n",
    "        # be careful when using np.empty... see documentation. np.zeros may be better\n",
    "        self.p_ak\t\t\t= np.zeros((self.n_classes_, self.n_components_)) + (1.0 / self.n_classes_)\n",
    "    \n",
    "        \n",
    "        if self.cov_type == \"full\":\n",
    "            self.covariances\t= np.tile(np.cov(X, rowvar = False), (self.n_components_, 1, 1))\n",
    "        elif self.cov_type == \"tied\":\n",
    "            self.covariances\t= {'covariance': np.cov(X, rowvar = False), 'n_components': self.n_components_}\n",
    "        elif self.cov_type == \"diag\":\n",
    "            self.covariances\t= np.tile(diag(np.cov(X, rowvar = False)), (self.n_components_, 1))\n",
    "        elif self.cov_type == \"diag_tied\":\n",
    "            self.covariances\t= {'covariance': diag(np.cov(X, rowvar = False)), 'n_components': self.n_components_}\n",
    "        elif self.cov_type == \"spherical\":\n",
    "            m = (np.sum(X, axis = 0)/self.n_features)\n",
    "            dist = np.sqrt(np.sum(np.square(X-m), axis = 1))\n",
    "            self.covariances\t= np.tile(np.average(dist), (self.n_components_))\n",
    "        elif self.cov_type == \"spherical_tied\":\n",
    "            m = (np.sum(X, axis = 0)/self.n_features)\n",
    "            dist = np.sqrt(np.sum(np.square(X-m), axis = 1))\n",
    "            self.covariances\t= {'covariance': np.average(dist), 'n_components': self.n_components_}\n",
    "        \n",
    "        \n",
    "        self.components\t\t= 1.0 / self.n_components_\n",
    "    \n",
    "        for _ in range(n_init):\n",
    "            # we use k-means++ as initialization for the k-means (default)\n",
    "            yield np.asarray(KMeans(n_clusters = self.n_components_).fit(X).cluster_centers_)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-09502ee23fb3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-09502ee23fb3>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    list(: :5)\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
